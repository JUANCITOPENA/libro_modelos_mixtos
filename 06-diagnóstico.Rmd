# Diagnóstico del modelo de regresión de efectos mixtos {#reg-diagnos}

El diagnóstico del modelo de regresión es uno de un conjunto de procedimientos disponibles para el análisis de regresión que buscan evaluar la validez de un modelo previamente ajustado. Esta evaluación puede ser una exploración de los supuestos estadísticos del modelo. El objetivo de este capitulo consiste en introducir al lector los distintos métodos de diagnostico del modelo, los cuales permitiran identificar aquel modelo que represente sus datos con una mayor precisión.

```{r Paquetes usados, echo = FALSE, eval = TRUE, message = FALSE, warning = FALSE}

library(dplyr)
library(ggplot2)
library(ggforce)
library(kableExtra)
library(DT)
library(patchwork)
library(demoR)
library(ggeffects)
library(showtext) # Link donde hay varias fuentes de ejemplo (https://github.com/yixuan/showtext)
font_add_google('Gochi Hand', 'gochi')
showtext_auto()
```


## Supuestos del modelo de regresión

Existen un conjunto de supuestos cuando se modela la relación entre una variable respuesta y un regresor. Estos supuestos son esencialmente condiciones que deben cumplirse. Cuando no es el caso, las estimaciones y predicciones pueden comportarse mal e incluso pueden tergiversar por completo los datos. El diagnóstico de regresión puede revelar el problema y, a menudo, señalar el camino hacia las soluciones.

Si un modelo de regresión ajustado representa adecuadamente los datos, sus residuos deberan:

1. Tener varianza constante (homogeneidad de la varianza);
2. Estar aproximadamente distribuidos de forma normal y;
3. Ser independientes el uno del otro.

Por tanto los supuestos del modelo de regresión se examinan a partir de los residuos que resultan del ajuste previo.

## Los residuos

Los residuos son la base de la mayoría de los métodos de diagnóstico. Estos pueden ser de distinto tipo. Los residuos más básicos son los denominados _residuos ordinarios_, $\hat{\epsilon}_{i}$, el cual se define como la diferencia entre el valor observado, $y_{i}$, y su correspondiente valor estimado por el modelo, $\hat{\mu}_{i}$, así:

\begin{align*}
\hat{\epsilon}_{i} = y_{i} - \hat{\mu}_{i}, i = 1, 2, ..., n
\end{align*}

donde $\hat{\mu}_{i}$ es igual a $x^{'}_{i}\hat{\beta}$. A continuación, se presenta una representación gráfica de $\hat{\epsilon}_{i}$: 

```{r, echo = FALSE, eval = TRUE, message = FALSE, warning = FALSE, fig.showtext = TRUE, out.width = "80%", fig.align = "center", fig.cap = "Representación gráfica de los residuos, del valor estimado y del valor observado."}

Residuos <- tibble::tribble(
  ~x, ~y, ~z,
  'A', 0.0, 0.25,
  'A', 0.25, 0.5,
  'A', 0.5, 0.75,
  'A', 0.75, 1.0,
  'A', 1.0, 1.25
) %>%
  ggplot2::ggplot(aes(x = y, y = z, group = x)) +
  geom_line(colour = 'gray64', size = 1.4, alpha = 0.7) +
  geom_point(colour = 'gray64', size = 2.8, alpha = 0.7) +
  geom_point(aes(x = 0.0, y = 0.4), colour = 'red', size = 2.8, alpha = 0.5) +
  geom_point(aes(x = 0.25, y = 0.28), colour = 'red', size = 2.8, alpha = 0.5) +
  geom_point(aes(x = 0.5, y = 1.0), colour = 'red', size = 2.8, alpha = 0.5) +
  geom_point(aes(x = 0.75, y = 0.9), colour = 'red', size = 2.8, alpha = 0.5) +
  geom_point(aes(x = 1.0, y = 1.1), colour = 'red', size = 2.8, alpha = 0.5) +
  annotate(geom = 'rect', xmin = 0.0, xmax = 0.0, ymin = 0.27, ymax = 0.38, colour = 'black', fill = 'black', alpha = 0.4, size = 0.8, linetype = 'dashed') +
  annotate(geom = 'rect', xmin = 0.25, xmax = 0.25, ymin = 0.48, ymax = 0.30, colour = 'black', fill = 'black', alpha = 0.4, size = 0.8, linetype = 'dashed') +
  annotate(geom = 'rect', xmin = 0.5, xmax = 0.5, ymin = 0.77, ymax = 0.97, colour = 'black', fill = 'black', alpha = 0.4, size = 0.8, linetype = 'dashed') +
  annotate(geom = 'rect', xmin = 0.75, xmax = 0.75, ymin = 0.97, ymax = 0.93, colour = 'black', fill = 'black', alpha = 0.4, size = 0.8, linetype = 'dashed') +
  annotate(geom = 'rect', xmin = 1.0, xmax = 1.0, ymin = 1.23, ymax = 1.15, colour = 'black', fill = 'black', alpha = 0.4, size = 0.8, linetype = 'dashed') +
  geom_curve(x = 0.5, xend = 0.5, y = 0.58, yend = 0.72, arrow = arrow(length = unit(0.1, 'inch')), size = 0.5, color = 'black', curvature = -0.5) +
  annotate(geom = 'text', x = 0.6, y = 0.58, label = 'Valor estimado', family = 'gochi', size = 8.8, colour = 'black') +
  geom_curve(x = 0.5, xend = 0.5, y = 1.18, yend = 1.03, arrow = arrow(length = unit(0.1, 'inch')), size = 0.5, color = 'black', curvature = -0.5) +
  annotate(geom = 'text', x = 0.39, y = 1.18, label = 'Valor observado', family = 'gochi', size = 8.8, colour = 'black') +
  geom_curve(x = 0.42, xend = 0.49, y = 0.88, yend = 0.88, arrow = arrow(length = unit(0.1, 'inch')), size = 0.5, color = 'black', curvature = -0.2) +
  annotate(geom = 'text', x = 0.32, y = 0.88, label = 'Residuo ordinario', family = 'gochi', size = 8.8, colour = 'black') +
  theme_bw() +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank())
Residuos
```

Luego los residuos ordinarios se escalan con el fin de que su interpretación no dependa de las unidades de medida de la variable respuesta. El proceso de estandarización consiste en dividir el residuo ordinario, $\hat{\epsilon}_{i}$, por la expresión $\sigma\sqrt{(1-h_{i})}$, donde ${\sigma}$ corresponde a la desviación estandar verdadera y $h_{i}$ al ~~apalancamiento o valor de sombrero~~. Los residuos obtenidos de esta manera se denominan como _residuos estandarizados_.

Sin embargo la verdadera desviación estándar rara vez se conoce. Por lo tanto, el escalado se puede realizar utilizando un estimador del mismo, es decir $\hat{\sigma}$. Los residuos obtenidos de esta manera se denominan como _residuos estudentizados_, los cuales a su vez se dividen en dos: los _residuos internamente estudentizados_ y los _residuos externamente estudentizados_. La tabla a continuación, resume las formas básicas de los residuos escalados:

```{r Tabla de tipos de residuos, echo = FALSE, eval = TRUE, message = FALSE, warning = FALSE}

Tabla_1 <- tibble::tribble(
  ~x,
  '$\\frac{\\hat\\epsilon_i}{\\sigma\\sqrt{(1-h_i)}}$',
  '$\\frac{\\hat\\epsilon_i}{\\hat\\sigma\\sqrt{(1-h_i)}}$',
  '$\\frac{\\hat\\epsilon_i}{\\hat\\sigma_{(-i)}\\sqrt{(1-h_i)}}$',
)
rownames(Tabla_1) <- c('Estandarizado', 'Internamente estudentizado', 'Externamente estudentizado')

kable(Tabla_1, col.names = 'Formula matemática') %>%
  kable_styling(full_width = FALSE) %>%
  footnote(symbol = c('En el residuo internamente estudentizado, $\\hat\\sigma$ denota\n una estimación de $\\sigma$ basada en todas las observaciones;', 'En el residuo externamente estudentizado, $\\hat\\sigma_{(-i)}$ es una\n estimación obtenida luego de excluir la i-ésima observación\n de los cálculos.'))
```
<!--
~~Para obtener los residuos ordinarios, se puede emplear la función general `residuals()`. Luego las funciones `rstandard()` y `rstudent()` devuelven los residuos estandarizados y estudentizados, respectivamente. Para ello, es necesario ajustar inicialmente el modelo de regresión.~~
-->
Se usara la base de datos `hsb` del paquete `merTools` para entender mejor de que tratan los residuos, así como también los métodos de diagnosticos que explicaremos más adelante en este capitulo. A continuación podra ver la base de datos a usar:

<!--
Los datos a usar fueron recopilados por Raudenbush y Bryk (2012). Estos consisten en una encuesta realizada a 7185 estudiantes de secundaria en Estados Unidos de 160 escuelas (alrededor de 45 estudiantes por escuela). Las variables son las siguientes:

schid: un vector numérico que corresponde a 160 valores únicos (las 160 escuelas);
mathach: un vector numérico que corresponde al rendimiento en una evaluación estandarizada de matemáticas;
female: un vector numérico codificado en 0 para masculino y 1 para femenino;
ses -> una medida numerica del estatus socioeconómico del estudiante;
minority: un vector numérico codificado en 0 para estudiantes blancos y 1 para estudiantes no blancos;
schtype: un vector numérico codificado en 0 para escuelas públicas y 1 para escuelas privadas;
meanses: un valor numérico, el SES promedio para cada escuela en el conjunto de datos;
size: un número que indica la cantidad de estudiantes en cada escuela.
-->

```{r Se carga la base de datos a usar, echo = FALSE, eval = TRUE, message = FALSE, fig.align = "center"}

library(merTools) # Paquete que contiene la base de datos a usar en los ejemplos
data('hsb')

datatable(hsb, filter = 'top', options = list(autoWidth = TRUE),
  caption = htmltools::tags$caption(
    style = 'caption-side: bottom; text-align: center;',
    'Tabla 1: ', htmltools::em('Conjunto de datos de una encuenta realizado a 7185 estudiantes de secundaria en Estados Unidos de 160 escuelas.')
  )
)
```

<br>

Se puede entender bien la lógica de los que son los residuos ajustando un modelo de regresión simple.

<div style="-moz-box-shadow: 1px 1px 3px 2px #ffff00;
  -webkit-box-shadow: 1px 1px 3px 2px #ffff00;
  box-shadow:         1px 1px 3px 2px #ffff00;">

```{block2, type='rmdnote'}

El diagnóstico del modelo de regresión aborda la adecuación de un modelo estadístico una vez se han ajustado los datos. De hecho, el ajuste de un modelo debe verse como un proceso iterativo en el que se ajusta el modelo, se evalúan sus residuos y se mejora. Así hasta llegar a un modelo óptimo.
```

</div>

Suponga que se quiere poner en relación dos variables: la variable $x_{1}$ que representa el nivel socio-económico de los estudiantes (`ses`), y la variable $y$, que es el rendimiento de los mismos estudiantes en una prueba de matemáticas (`mathach`). Para facilitar este análisis (y los posteriores) se asumira que $x_{1}$ es una variable continua que toma valores entre `-4` y `+4`, donde valores cercanos a `0` indican nivel socio-económico medio, cercanos a `+4` indican nivel socio-económico alto y cercanos a `-4` indican nivel socio-económico bajo.

El modelo de regresión simple aplicado a este ejemplo se puede representar así:

\begin{align} \label{mod2}
y_i &\sim N(\mu_i, \sigma^2), \\ 
\mu_i &= \beta_0 + \beta_1 x_{1i}, \\
\sigma^2 &= \text{constante}
\end{align}

El codigó en `R` para ajustar el anterior modelo se presenta a continuación:

```{r Modelo de regresión simple para entender lo que son los residuos, echo = TRUE, eval = TRUE, message = FALSE}

Modelo_simple <- lm(mathach ~ ses, data = hsb)
summary(Modelo_simple)
```

Luego, los residuos (en este caso los residuos ordinarios) se pueden obtener con las siguientes funciones genericas:

```{r Funciones para obtener los valores residuales, echo = TRUE, eval = FALSE, message = FALSE}

muestra_aleatoria$val_predicho <- predict(Modelo_simple)
muestra_aleatoria$res_ordinario <- residuals(Modelo_simple)
```

La gráfica a continuación presenta los valores observados y estimados en el rendimiento de los estudiantes en una prueba de matemáticas según su nivel socio-económico, siendo la misma una representación gráfica similar a la presentada en la **Figura 6.1**:

<div style="-moz-box-shadow: 1px 1px 3px 2px #808080;
  -webkit-box-shadow: 1px 1px 3px 2px #808080;
  box-shadow:         1px 1px 3px 2px #808080;">

```{block2, type='rmdwarning'}

Tenga en cuenta que se bien el modelo se ajusto con las 7185 valores observados, la gráfica a continuación solo presenta 150 valores. Esto debido a que al no restringir por este valor, la gráfica se presentaba muy saturada de valores observados y estimados.
```

</div>

```{r, echo = FALSE, eval = TRUE, message = FALSE, fig.align = "center", fig.cap = "Valores obserados y estimados en el rendimiento en una prueba matemática según el nivel socio-económico del estudiante."}

set.seed(1234)
muestra_aleatoria <- hsb %>%
  distinct %>% 
  sample_n(150) # Se eligio al azar 150 filas debido a que si dejabamos todos los 7185 datos, no se veia bien la gráfica

Modelo_simple <- lm(mathach ~ ses, data = muestra_aleatoria)

muestra_aleatoria$val_predicho <- predict(Modelo_simple)
muestra_aleatoria$res_ordinario <- residuals(Modelo_simple)

# Se gráfica los valores reales y predichos
ggplot(data = muestra_aleatoria, aes(x = ses, y = mathach)) +
  geom_smooth(method = 'lm', se = FALSE, color = 'lightgrey', size = 1.8) + # Se incluye la línea de regresión
  geom_segment(aes(xend = ses, yend = val_predicho), alpha = 0.4) + # Se conectan los valores reales de los predichos con lineas verticales
  geom_point(aes(alpha = abs(res_ordinario)), size = 3.2) + # Se incluyen los valores observados, indicando (con la claridad en el color) el valor del residuo
  guides(alpha = FALSE) + # Se quita la leyenda por la opción anterior de dar claridad con base al valor del residuo
  geom_point(aes(y = val_predicho), shape = 1, size = 2.4) + # Se incluyen los valores estimados
  theme_bw() +
  labs(x = 'Nivel socio-económico', y = 'Valores observados y estimados para el\n rendimiento de estudiantes en la prueba') +
  theme(axis.text = element_text(size = 12, color = 'black', face = 'bold'), 
        axis.title = element_text(size = 12, face = 'bold'))
```

La gráfica anterior representa la relación existente entre el rendimiento académico y el nivel socio-económico del estudiante. Claramente se puede observar que a mayor nivel socio-económico, mejor es el rendimiento del estudiante. Una vez ajustado el modelo de regresión, y como se puede observar en la anterior gráfica, se tienen los valores observados (puntos con relleno), los valores estimados (puntos sin relleno) y el residuo (representado por una línea vertical que une a los valores observados con los estimados). Por tanto, puede imaginar ahora que cada dato (valor observado) tiene un valor estimado y un residuo (residuo ordinario en este caso) como se detalla a continuación:

```{r Tabla de valores obtenidos con el modelo de regresión ajustado, echo = FALSE, eval = TRUE, message = FALSE, fig.align = "center"}

Tabla_2 <- muestra_aleatoria %>%
  dplyr::select(mathach, val_predicho, res_ordinario) %>%
  slice(1:4)
kable(Tabla_2, col.names = c('Rendimiento real', 'Rendimiento estimado', 'Residuo ordinario')) %>%
  kable_styling(full_width = FALSE)
```

Luego dichos residuos se consideran como elementos clave en la evaluación del modelo ajustado. Estos suelen emplearse en los métodos de diagnosticos del modelo de regresión mediante pruebas de hipótesis acompañadas de inferencia visual (gráficos). Por ejemplo, la figura a continuación muestra una de las gráficas comunmente usadas en los métodos de diagnostico:

```{r, echo = FALSE, eval = TRUE, message = FALSE, fig.align = "center", out.width = "80%", fig.cap = " Grafica de residuos ordinarios vs Valores estimados."}

ggplot(data = muestra_aleatoria, aes(x = val_predicho, y = res_ordinario)) +
  geom_point(aes(alpha = abs(res_ordinario)), size = 3.2) +
  guides(alpha = FALSE) +
  stat_smooth(method = 'loess', se = FALSE, color = 'red', size = 1.4) +
  geom_hline(yintercept = 0, color = 'black', linetype = 'dashed', size = 1.4) +
  labs(x = 'Valores estimados', y = 'Residuos ordinarios') +
  theme_bw() +
  theme(axis.text = element_text(size = 12, color = 'black', face = 'bold'), 
        axis.title = element_text(size = 12, face = 'bold'))
```

<div style="-moz-box-shadow: 1px 1px 3px 2px #ffff00;
  -webkit-box-shadow: 1px 1px 3px 2px #ffff00;
  box-shadow:         1px 1px 3px 2px #ffff00;">

```{block2, type='rmdnote'}

Existe una gran variedad de gráficos (como la presentada anteriormente) lo que refleja el hecho de que ningún gráfico de diagnóstico es apropiado para todos los propósitos.
```

</div>

Veremos la interpretación de la misma con más detalle a continuación.

## Diagnóstico del modelo de regresión: prueba de hipótesis e inferencia visual

Como es sabido, la inferencia estadística clásica consiste en formular inicialmente un juego de hipótesis (hipótesis nula y alternativa), y calcular posteriormente un estadístico de prueba del cual se deriva un `valor p` que permitira concluir en relación a las hipótesis planteadas. Este proceso tiene su análogo en inferencia visual.

Suponga que el interés consiste en verificar alguna suposición sobre el modelo ajustado, por ejemplo, la homogeneidad de la varianza residual. Para ello se plantea como hipótesis nula el cumplimiento de dicha homogeneidad, mientras que la hipótesis alternativa abarca cualquier violación de este supuesto. Para la inferencia visual, el estadístico de prueba corresponde a una gráfica que muestra un aspecto del supuesto que se desea verifcar, y permite al observador distinguir entre escenarios bajo la hipótesis nula y la alternativa.

A continuación se mostrará como llevar a cabo el diagnóstico del modelo de regresión empleando tanto pruebas de hipótesis como inferencia visual. Para ello, haremos uso de nuevo de la base de datos anteriormente mencionada `hsb`.

### Ajustando el modelo

Vimos anteriormente en este capitulo que era posible determinar si el rendimiento de los estudiantes en una prueba de matemáticas (`mathach`) estaba relacionada con su nivel socio-económico (`ses`). Se considerará ahora la posibilidad de que la relación entre el rendimiento y el nivel socio-económico del estudiante varien según las características de la escuela, específicamente, si la escuela es una escuela pública o una escuela privada (`schtype`). Un buen punto de partida consiste es ver la relación entre el rendimiento y el nivel socio-económico por separado para cada escuela:

```{r, echo = FALSE, eval = TRUE, message = FALSE, fig.align = "center", out.width = "80%", fig.cap = "Diagrama de dispersión del rendimiento matemático según el nivel socio-económico en escuelas públicas."}

set.seed(1234)
Grafica_1 <- hsb %>%
  filter(schtype == 0) %>%
  distinct(schid) %>%
  sample_n(12) %>% # Se eligio al azar 12 escuelas públicas
  left_join(hsb, 'schid') %>%
  ggplot(aes(x = ses, y = mathach, color = schid, fill = schid)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = 'lm', se = FALSE, color = 'gray64') +
  facet_wrap(~ schid) +
  theme_bw() +
  theme(legend.position = 'none') +
  labs(x = 'Nivel socio-económico', y = 'Rendimiento del estudiante en\n la prueba de matemáticas', title = 'Escuelas públicas') +
  theme(axis.text = element_text(size = 8, color = 'black', face = 'bold'), 
        axis.title = element_text(size = 10, face = 'bold'),
        plot.title = element_text(size = 10, face = 'bold'))
Grafica_1  
```

```{r, echo = FALSE, eval = TRUE, message = FALSE, fig.align = "center", out.width = "80%", fig.cap = "Diagrama de dispersión del rendimiento matemático según el nivel socio-económico en escuelas privadas."}

set.seed(1234)
Grafica_2 <- hsb %>%
  filter(schtype == 1) %>%
  distinct(schid) %>%
  sample_n(12) %>% # Se eligio al azar 12 escuelas privadas
  left_join(hsb, 'schid') %>%
  ggplot(aes(x = ses, y = mathach, color = schid, fill = schid)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = 'lm', se = FALSE, color = 'gray64') +
  facet_wrap(~ schid) +
  theme_bw() +
  theme(legend.position = 'none') +
  labs(x = 'Nivel socio-económico', y = 'Rendimiento del estudiante en\n la prueba de matemáticas', title = 'Escuelas privadas') +
  theme(axis.text = element_text(size = 8, color = 'black', face = 'bold'), 
        axis.title = element_text(size = 10, face = 'bold'),
        plot.title = element_text(size = 10, face = 'bold'))
Grafica_2
```

En cada panel, la línea representa un ajuste lineal por mínimos cuadrados a los datos. El número en la parte superior corresponde a la identificación de la escuela (en este caso se han elegido doce escuelas para cada tipo). Claramente parece haber una diferencia entre la escuelas públicas y privadas: las líneas para las escuelas públicas parecen tener pendientes más pronunciadas. Esto hace pensar que un modelo de efectos mixtos con intercepto y pendiente aleatoria podría ser adecuado para modelar este tipo de datos.

Por tal motivo, el modelo de regresión de efectos mixtos aplicado a este ejemplo se puede representar así:

\begin{align*} 
y_{ij} &\sim  N(\mu_{ij}, \sigma^2), \\ 
\mu_{ij} &= \beta_0 + \beta_1 x_{ij} + b_{0i} + b_{1i} x_{ij}, \\
\left (
\begin{matrix}
b_{0} \\ b_{1}
\end{matrix} 
\right ) &\sim 
N\left [ \left ( \begin{matrix}
0 \\ 0
\end{matrix} \right ),
\left ( \begin{matrix}
\sigma^2_{b0} & \sigma_{b01} \\ 
\sigma_{b01} & \sigma^2_{b1}
\end{matrix} \right )
\right ]
\end{align*}

Esta ecuación representa la relación existente entre el rendimiento acádemico y el nivel socio-económico de los estudiantes. La variable respuesta, $y_{ij}$, es el rendimiento del estudiante, $i$, en la escuela $j$.

El codigó en `R` para ajustar el anterior modelo se presenta a continuación. Se hara uso del paquete `lme4` ya mencionado en el capitulo 3 del presente libro:

```{r Cambio en la variable tipo de escuela, echo=FALSE, eval=TRUE, message=FALSE}

hsb <- hsb %>% # Necesite hacer este cambió
  mutate(schtype = case_when(
    schtype == 0 ~ 'Pública',
    schtype == 1 ~ 'Privada'
  ))
```

```{r Modelo de regresión mixto ajustado, echo = TRUE, eval = TRUE, message = FALSE}

library(lme4)
Modelo_mixto <- lmer(mathach ~ ses + (ses | schtype),
                     REML = TRUE,
                     data = hsb)
```

La siguiente figura, obtenida a partir del modelo anteriormente ajustado, pone de manifiesto la posibilidad real y plausible de que el intercepto y la pendiente varíen según las características de cada escuela (privada o pública): 

```{r, echo = FALSE, eval = TRUE, message = FALSE, fig.align = "center", fig.cap = "Grafica del modelo de regresión ajustado para dos escuelas."}

hsb$pred_inter_pend_aleato <- predict(Modelo_mixto)

Grafica_mixta <- ggplot(data = hsb, aes(x = ses, y = pred_inter_pend_aleato, color = schtype, fill = schtype)) +
  geom_point(aes(x = ses, y = mathach, color = schtype), alpha = 0.4) +
  geom_line(size = 1.4) +
  geom_vline(xintercept = 0, linetype = 'dashed') +
  #geom_curve(x = -2.4, xend = 0.0, y = 15.0, yend = 14.0, arrow = arrow(length = unit(0.1, 'inch')), size = 0.5, color = 'black', curvature = 0.0) +
  #annotate(geom = 'text', x = -2.5, y = 15.2, label = 'beta[0]', parse = TRUE, colour = 'black', size = 5.4) +
  #scale_color_manual(values = c('yellow', 'cyan')) +
  #scale_fill_manual(values = c('yellow', 'cyan')) +
  theme_bw() +
  #facet_wrap(~ schtype) +
  labs(x = 'Nivel socio-económico', y = 'Rendimiento del estudiante en\n la prueba de matemáticas') +
  theme(axis.text = element_text(size = 10, color = 'black', face = 'bold'), 
        axis.title = element_text(size = 12, color = 'black', face = 'bold'),
        legend.text = element_text(size = 7, color = 'black'),
        legend.title = element_text(size = 10, color = 'black', face = 'bold'))
Grafica_mixta
```

Luego de ajustado el modelo de regresión, el procedimiento a seguir corresponde a evaluar el cumplimiento de los supuestos del mismo mediante métodos de diagnóstico.

### Varianza constante de los residuos mediante prueba de hipótesis



### Varianza constante de los residuos mediante inferencia visual

Uno de los supuestos del modelo de regresión es la varianza constante de los residuos. Para comprobar dicho supuesto, se suele emplear la gráfica de residuos contra los valores estimados. La misma es considerada como la gráfica de diagnóstico más básica. A continuación podrá observar varios ejemplos de la misma:

```{r, echo = FALSE, eval = TRUE, message = FALSE, fig.align = "center", fig.cap = "Representación visual de la gráfica de residuos contra los valores estimados."}

set.seed (100)

Normal <- function(n, Lower, Upper) { # Función para simular datos con distribución normal
    x = rnorm(n, 5, 1)
    y = rnorm(n, 0, 1)
    data.frame(x, y)
}

Graf_residuo_1 <- Normal(200) %>%
  ggplot(aes(x = x, y = y)) +
  geom_hline(yintercept = 0, color = "black", linetype = "dashed", size = 0.8) +
  geom_point(colour = 'black', size = 2.8, alpha = 0.4) +
  labs(x = 'Valores estimados', y = 'Residuos', title = 'A') +
  theme_bw() +
  theme(axis.text = element_blank(), 
        axis.title = element_text(size = 12, face = 'bold'),
        plot.title = element_text(size = 12, face = 'bold'),
        axis.ticks = element_blank())

No_lineal <- function(n, Lower, Upper) { # Función para simular datos con valores no lineales
    x = rnorm(n, 5, 1)
    y = (x-3)^3/10 + rnorm(n, 0, 1)
    data.frame(x, y)
}

Graf_residuo_2 <- No_lineal(200) %>%
  ggplot(aes(x = x, y = y)) +
  geom_hline(yintercept = 0, color = "black", linetype = "dashed", size = 0.8) +
  geom_point(colour = 'black', size = 2.8, alpha = 0.4) +
  labs(x = 'Valores estimados', y = 'Residuos', title = 'B') +
  theme_bw() +
  theme(axis.text = element_blank(), 
        axis.title = element_text(size = 12, face = 'bold'),
        plot.title = element_text(size = 12, face = 'bold'),
        axis.ticks = element_blank())

Val_atipico <- tibble::tribble(
  ~x, ~y,
  2, 4.0)

Graf_residuo_3 <- Normal(200) %>%
  ggplot(aes(x = x, y = y)) +
  geom_hline(yintercept = 0, color = 'black', linetype = 'dashed', size = 0.8) +
  geom_point(colour = 'black', size = 2.8, alpha = 0.4) +
  geom_point(data = Val_atipico, aes(x = x, y = y), colour = 'red', size = 2.8, alpha = 0.4) +
  facet_zoom(xlim = c(0.0, 4.0), ylim = c(3.0, 5.0)) +
  labs(x = 'Valores estimados', y = 'Residuos', title = 'C') +
  theme_bw() +
  theme(axis.text = element_blank(), 
        axis.title = element_text(size = 12, face = 'bold'),
        plot.title = element_text(size = 12, face = 'bold'),
        axis.ticks = element_blank())

(Graf_residuo_1 | Graf_residuo_2) / Graf_residuo_3
```

Si se cumple el supuesto de varianza constante de los residuos, estos se dispersarían de forma aleatoria alrededor de la línea central (como si se tratara de una nube de puntos) sin un patrón obvio, como se puede observar en la figura 6.7 __A__. La varianza no constante se diagnosticaría si la variabilidad de los residuos en el gráfico mostraran un patrón no aleatorio, como por ejemplo, si hubiera una curvatura presente (figura 6.7 __B__), o bien, si los residuos cambiaran de forma abrupta a medida que aumentan los valores estimados. Finalmente, un patrón inusual puede ser causado por un valor atípico. En el ejemplo visual anterior (figura 6.7 __C__), se muestra un valor atípico obvio.

En el ejemplo planteado usando la base de datos `hsb`, esta gráfica se muestra en las figuras 6.8 __A__ y 6.8 __C__, basados en dos tipos de residuos (ordinarios y pearson):

```{r Tipos de Residuos y valores esimados, echo = FALSE, eval = TRUE, message = FALSE}

hsb$val_estimado <- fitted(Modelo_mixto)
hsb$res_ordinario <- resid(Modelo_mixto, type = "response")
hsb$res_pearson <- resid(Modelo_mixto, type = "pearson")
```

```{r, echo = FALSE, eval = TRUE, message = FALSE, warning = FALSE, fig.align = "center", fig.cap = "Gráficos residuales para el modelo de efectos mixtos (a) entre los residuos ordinarios contra los valores estimados (b) residuos ordinarios en cada tipo de escuela (c) residuos pearson contra los valores estimados (d) residuos pearson en cada tipo de escuela."}

demo_code('
Grafica_A <- ggplot(data = hsb, aes(x = val_estimado, y = res_ordinario)) +
  geom_point(alpha = 0.4, size = 2.0) +
  stat_smooth(method = "loess", se = FALSE, color = "red", size = 0.8) +
  geom_hline(yintercept = 0, color = "black", linetype = "dashed", size = 0.8) +
  labs(x = "Valores estimados", y = "Residuos ordinarios", title = "A") +
  theme_bw() +
  theme(axis.text = element_text(size = 8, face = "bold"), 
        axis.title = element_text(size = 8, face = "bold"),
        plot.title = element_text(size = 8, face = "bold"))
') %>%
  hlt_args(color = 'gray') %>%
  hlt_funs(color = 'deeppink', underline = TRUE) %>%
  hlt_regexp('val_estimado', background = 'cyan') %>%
  hlt_regexp('res_ordinario', background = 'cyan') %>%
  hlt_fixed('ggplot') %>%
  hlt_fixed('stat_smooth')

demo_code('
Grafica_B <- ggplot(data = hsb, aes(x = schtype, y = res_ordinario, color = schtype, fill = schtype)) +
  geom_boxplot(alpha = 0.4) +
  scale_color_manual(values = c("black", "yellow")) +
  scale_fill_manual(values = c("black", "yellow")) +
  labs(x = "Tipo de escuela", y = "Residuos ordinarios", title = "B") +
  theme_bw() +
  theme(axis.text = element_text(size = 8, face = "bold"), 
        axis.title = element_text(size = 8, face = "bold"),
        plot.title = element_text(size = 8, face = "bold"),
        legend.text = element_text(size = 6, face = "bold"),
        legend.title = element_text(size = 6, face = "bold"))
') %>%
  hlt_args(color = 'gray') %>%
  hlt_funs(color = 'deeppink', underline = TRUE) %>%
  hlt_regexp('res_ordinario', background = 'cyan') %>%
  hlt_fixed('ggplot')

Grafica_C <- ggplot(data = hsb, aes(x = val_estimado, y = res_pearson)) +
  geom_point(alpha = 0.4, size = 2.0) +
  stat_smooth(method = "loess", se = FALSE, color = "red", size = 0.8) +
  geom_hline(yintercept = 0, color = "black", linetype = "dashed", size = 0.8) +
  labs(x = "Valores estimados", y = "Residuos Pearson", title = "C") +
  theme_bw() +
  theme(axis.text = element_text(size = 8, face = "bold"), 
        axis.title = element_text(size = 8, face = "bold"),
        plot.title = element_text(size = 8, face = "bold"))

Grafica_D <- ggplot(data = hsb, aes(x = schtype, y = res_pearson, color = schtype, fill = schtype)) +
  geom_boxplot(alpha = 0.4) +
  scale_color_manual(values = c("black", "yellow")) +
  scale_fill_manual(values = c("black", "yellow")) +
  labs(x = "Tipo de escuela", y = "Residuos pearson", title = "D") +
  theme_bw() +
  theme(axis.text = element_text(size = 8, face = "bold"), 
        axis.title = element_text(size = 8, face = "bold"),
        plot.title = element_text(size = 8, face = "bold"),
        legend.text = element_text(size = 6, face = "bold"),
        legend.title = element_text(size = 6, face = "bold"))

(Grafica_A | Grafica_B) / (Grafica_C | Grafica_D)
```

En relación al código presentado anteriormente, tenga en cuenta lo siguiente:

+ Las gráficas se realizaron usando la función `ggplot()` (aquí subrayado en color amarillo) del paquete `ggplot2`;
+ Luego en la asignación estética (`aes`), se proporcionó los valores estimados y los residuos pearson u ordinarios (aquí subrayados en color azul), datos que se obtuvieron mediante previo ajuste del modelo;
+ La línea discontinua en las gráficas superior e inferior izquierda, es la línea horizontal a través de $\hat{\epsilon}_{i} = 0$ (es decir, donde la diferencia entre los valores observados y estimados son iguales a cero), siendo el mismo el caso ideal;
+ La línea continua en rojo en las gráficas superior e inferior izquierda, obtenidas a partir de la función `stat_smoot` (aquí subrayado en amarillo), representan una curva suave ajustada mediante el método `loess`, que indica la relación de los valores estimados con los residuos.

En general, los gráficos anteriores se evalúan de forma informal con respecto a la presencia o ausencia de patrones específicos y/o puntos de datos periféricos o aislados. Respecto a la línea de referencia en cero y la línea ajustada mediante el método de `loess`, estas deberían parecerse. Por otro lado en cuanto al gráfico de caja y bigotes (parte superior e inferior derecha de la anterior figura), si estas tienen aproximadamente el mismo centro y distancia intercuartil, como es el caso aquí, indicarían el cumplimiento de varianza constante de los residuos.

### Gráfica marginal del modelo

Una variación de la gráfica residual básica anterior es una donde se muestre la distribución condicional de la variable respuesta dado el ajuste del modelo. A esta se le conoce como gráfica marginal, en el sentido de que muestra la relación marginal entre la variable respuesta y cada regresor, y entre la variable respuesta y los valores estimados, previo ajuste del modelo.

```{r, echo = FALSE, eval = FALSE}

summary(Modelo_mixto)

library(car)

residualPlots(Modelo_simple)

marginalModelPlots(Modelo_mixto)
```


<!--
En el ejemplo planteado usando la base de datos `hsb`, esta gráfica se muestra en la figuras 6.9 __A__ y 6.9 __B__ a continuación.

```{r, eval=TRUE, echo=FALSE, fig.align="center", fig.cap=".", message=FALSE, warning=FALSE}

demo_code('
Grafica_A <- ggplot(data = hsb, aes(x = res_pearson)) +
  geom_histogram(aes(y = ..density..), colour = "gray47", fill = "gray80", binwidth = 5) +
  stat_function(fun = dnorm, colour = "black", size = 1.4,
                args = list(mean = mean(hsb$res_pearson), sd = sd(hsb$res_pearson))) +
  labs(x = "Residuos Pearson", y = "Frecuencia", title = "A") +
  theme_bw() +
  theme(axis.text = element_text(size = 8, face = "bold"), 
        axis.title = element_text(size = 8, face = "bold"),
        plot.title = element_text(size = 8, face = "bold"))
') %>%
  hlt_args(color = 'gray') %>%
  hlt_funs(color = 'deeppink', underline = TRUE) %>%
  hlt_regexp('res_pearson', background = 'cyan') %>%
  hlt_fixed('stat_function')

demo_code('
Grafica_B <- ggplot(data = hsb, aes(sample = res_pearson)) +
  stat_qq(distribution = qnorm, color = "gray54", alpha = 0.4, size = 4) +
  stat_qq_line(distribution = qnorm, color = "black", size = 1.8) +
  labs(x = "Cuantiles teóricos de una distribución normal", y = "Cuantiles de la distribución observada", title = "B") +
  theme_bw() +
  theme(axis.text = element_text(size = 8, face = "bold"), 
        axis.title = element_text(size = 8, face = "bold"),
        plot.title = element_text(size = 8, face = "bold"))
') %>%
  hlt_args(color = 'gray') %>%
  hlt_funs(color = 'deeppink', underline = TRUE) %>%
  hlt_regexp('res_pearson', background = 'cyan') %>%
  hlt_fixed('stat_qq') %>%
  hlt_fixed('stat_qq_line')

(Grafica_A | Grafica_B)
```

En relación al código presentado anteriormente, tenga en cuenta lo siguiente:

+ En la asignación estética (`aes`) usando el paquete `ggplot2`, se proporcionó los residuos pearson (aquí subrayados en color azul), datos que se obtuvieron mediante previo ajuste del modelo;
+.

<!--
No obstante los métodos gráficos permiten al analista descubrir no solo cuándo el modelo ajustado no cumple con el supuesto planteado, sino que también permite detectar cuál puede ser la causa del mismo, lo cual sería casi imposible a través de unicamente pruebas de hipótesis. 
-->

<!--  -->



